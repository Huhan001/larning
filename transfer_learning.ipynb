{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Huhan001/larning/blob/main/transfer_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v0sMJ11R2f6z"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import tensorflow_hub as hub\n",
        "\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UvuQGHD3Lfw"
      },
      "outputs": [],
      "source": [
        "link = 'https://storage.googleapis.com/ztm_tf_course/food_vision/101_food_classes_10_percent.zip'\n",
        "zip_in = tf.keras.utils.get_file(origin=link, extract= True, fname='101_food_classes_10_percent.zip')\n",
        "\n",
        "inspect = os.path.dirname(zip_in)\n",
        "\n",
        "base = os.path.dirname(zip_in)\n",
        "getin = os.path.join(base, '101_food_classes_10_percent')\n",
        "\n",
        "train = os.path.join(getin, 'train')\n",
        "test = os.path.join(getin, 'test')\n",
        "!find $test -type d -print"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U-o8FYAF-9Tp"
      },
      "source": [
        "Building flow of image using simple API not imageGenerator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "URVOOUqM9I5i",
        "outputId": "602f036c-7aac-40cd-84c1-fde56c706135"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 7575 files belonging to 101 classes.\n",
            "Found 25250 files belonging to 101 classes.\n"
          ]
        }
      ],
      "source": [
        "trainData = tf.keras.preprocessing.image_dataset_from_directory(directory= train,\n",
        "                                                              batch_size = 64,\n",
        "                                                              image_size = (150, 150),\n",
        "                                                              label_mode = 'categorical')\n",
        "testData = tf.keras.preprocessing.image_dataset_from_directory(directory= test,\n",
        "                                                              batch_size = 64,\n",
        "                                                              image_size = (150, 150),\n",
        "                                                              label_mode = 'categorical')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2B0YtPm934Z"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers.experimental import preprocessing\n",
        "\n",
        "data_augmentation = tf.keras.Sequential([\n",
        "    preprocessing.RandomFlip(\"horizontal\"),\n",
        "    preprocessing.RandomRotation(0.2),\n",
        "    preprocessing.RandomZoom(0.2),\n",
        "    preprocessing.RandomHeight(0.2),\n",
        "    preprocessing.RandomWidth(0.2)\n",
        "    # preprocessing.Rescaling(1./255) # keep for ResNet50V2, remove for EfficientNetB0\n",
        "], name = 'data_augmentation')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kSxBzOWFERWw"
      },
      "source": [
        "model checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EHu5k4IA-yID"
      },
      "outputs": [],
      "source": [
        "# Create checkpoint callback to save model for later use\n",
        "checkpoint_path = \"101_classes_10_percent_data_model_checkpoint\"\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
        "                                                         save_weights_only=True, # save only the model weights\n",
        "                                                         monitor=\"val_accuracy\", # save the model weights which score the best validation accuracy\n",
        "                                                         save_best_only=True) # only keep the best model weights on file (delete the rest)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Nm3phTH-1JP"
      },
      "source": [
        "Making the model now after processing the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nXk_5_HM-2T8",
        "outputId": "ff40c534-9455-4ba5-e1c3-4e001153c480"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "shape after base model KerasTensor(type_spec=TensorSpec(shape=(None, 150, 150, 3), dtype=tf.float32, name='input_layer'), name='input_layer', description=\"created by layer 'input_layer'\")\n",
            "After GlobalAveragePooling2D(): (None, 1280)\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "237/237 [==============================] - 105s 405ms/step - loss: 3.5853 - accuracy: 0.2218 - val_loss: 2.5764 - val_accuracy: 0.4055\n",
            "Epoch 2/10\n",
            "237/237 [==============================] - 94s 395ms/step - loss: 2.4877 - accuracy: 0.4231 - val_loss: 2.1828 - val_accuracy: 0.4621\n",
            "Epoch 3/10\n",
            "237/237 [==============================] - 93s 391ms/step - loss: 2.1191 - accuracy: 0.4925 - val_loss: 2.0345 - val_accuracy: 0.4849\n",
            "Epoch 4/10\n",
            "237/237 [==============================] - 133s 563ms/step - loss: 1.9098 - accuracy: 0.5284 - val_loss: 1.9714 - val_accuracy: 0.4945\n",
            "Epoch 5/10\n",
            "237/237 [==============================] - 106s 447ms/step - loss: 1.7589 - accuracy: 0.5637 - val_loss: 1.9290 - val_accuracy: 0.5038\n",
            "Epoch 6/10\n",
            "237/237 [==============================] - 94s 397ms/step - loss: 1.6120 - accuracy: 0.5954 - val_loss: 1.9108 - val_accuracy: 0.5056\n",
            "Epoch 7/10\n",
            "237/237 [==============================] - 99s 416ms/step - loss: 1.5209 - accuracy: 0.6185 - val_loss: 1.8972 - val_accuracy: 0.5101\n",
            "Epoch 8/10\n",
            "237/237 [==============================] - 94s 396ms/step - loss: 1.4371 - accuracy: 0.6385 - val_loss: 1.8876 - val_accuracy: 0.5118\n",
            "Epoch 9/10\n",
            "237/237 [==============================] - 108s 454ms/step - loss: 1.3525 - accuracy: 0.6631 - val_loss: 1.8834 - val_accuracy: 0.5138\n",
            "Epoch 10/10\n",
            "237/237 [==============================] - 100s 420ms/step - loss: 1.2972 - accuracy: 0.6737 - val_loss: 1.8840 - val_accuracy: 0.5122\n"
          ]
        }
      ],
      "source": [
        "base = tf.keras.applications.EfficientNetB0(include_top = False)\n",
        "base.trainable = False\n",
        "input = tf.keras.layers.Input(shape = (150,150,3), name ='input_layer')\n",
        "x = data_augmentation(input)\n",
        "x = base(x, training=False) # can remain false after data augmentation no need to train\n",
        "print('shape after base model {}'.format(input))\n",
        "\n",
        "# 4. If using ResNet50V2, add this to speed up convergence, remove for EfficientNet\n",
        "# x = tf.keras.layers.experimental.preprocessing.Rescaling(1./255)(inputs)\n",
        "\n",
        "x = tf.keras.layers.GlobalAveragePooling2D(name=\"global_average_pooling_layer\")(x)\n",
        "print(f\"After GlobalAveragePooling2D(): {x.shape}\")\n",
        "\n",
        "#6\n",
        "outputs = tf.keras.layers.Dense(101, activation=\"softmax\", name=\"output_layer\")(x)\n",
        "\n",
        "#7. Combine the inputs with the outputs into a model\n",
        "model_0 = tf.keras.Model(input, outputs)\n",
        "\n",
        "#8. Compile the model\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(),\n",
        "              metrics=[\"accuracy\"])\n",
        "\n",
        "history = model_0.fit(trainData,\n",
        "                      epochs= 10,\n",
        "                      validation_data= testData,\n",
        "                      validation_steps= len(testData),\n",
        "                      steps_per_epoch= len(trainData),\n",
        "                      callbacks=[checkpoint_callback])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oLMk0H80H4Wj"
      },
      "source": [
        "fine tunning builds upon the model checkpoint and plays with the layers from already trained models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iSreJSeRIBI4"
      },
      "outputs": [],
      "source": [
        "# Unfreeze all of the layers in the base model\n",
        "base.trainable = True\n",
        "\n",
        "# Refreeze every layer except for the last 5\n",
        "for layer in base.layers[:-5]:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6BB4LvzzIsnR"
      },
      "source": [
        "we must compile the model again after fine tuning it.  if at all the model doesnt perform well, we can always revert back to the previous model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bjubPcr6IrfL"
      },
      "outputs": [],
      "source": [
        "# Recompile model with lower learning rate\n",
        "model_0.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aR9Cj3dlJVGG"
      },
      "source": [
        "lets identify which models are trainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3h7Dy-dJX4W",
        "outputId": "5ae6d454-d75b-4c07-9302-65f42ceaf5f5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "input_layer True\n",
            "data_augmentation True\n",
            "efficientnetb0 True\n",
            "global_average_pooling_layer True\n",
            "output_layer True\n"
          ]
        }
      ],
      "source": [
        "# What layers in the model are trainable?\n",
        "for layer in model_0.layers:\n",
        "  print(layer.name, layer.trainable)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvmdGAlRJu1U"
      },
      "source": [
        "lets work out model now with fit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "y8vdu5PbJx2c",
        "outputId": "1e32a26e-ea74-4f0d-f45e-239143a30a6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/15\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting Bitcast cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2 cause there is no registered converter for this op.\n",
            "WARNING:tensorflow:Using a while_loop for converting ImageProjectiveTransformV3 cause there is no registered converter for this op.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "237/237 [==============================] - 105s 397ms/step - loss: 1.1367 - accuracy: 0.6936 - val_loss: 1.9240 - val_accuracy: 0.5183\n",
            "Epoch 11/15\n",
            "237/237 [==============================] - 91s 380ms/step - loss: 1.0299 - accuracy: 0.7216 - val_loss: 1.9206 - val_accuracy: 0.5199\n",
            "Epoch 12/15\n",
            "237/237 [==============================] - 92s 387ms/step - loss: 0.9493 - accuracy: 0.7419 - val_loss: 1.9426 - val_accuracy: 0.5204\n",
            "Epoch 13/15\n",
            "237/237 [==============================] - 89s 375ms/step - loss: 0.9129 - accuracy: 0.7535 - val_loss: 1.9392 - val_accuracy: 0.5238\n",
            "Epoch 14/15\n",
            "237/237 [==============================] - 89s 376ms/step - loss: 0.8663 - accuracy: 0.7650 - val_loss: 1.9471 - val_accuracy: 0.5233\n",
            "Epoch 15/15\n",
            "237/237 [==============================] - 92s 387ms/step - loss: 0.7961 - accuracy: 0.7827 - val_loss: 1.9638 - val_accuracy: 0.5212\n"
          ]
        }
      ],
      "source": [
        "fine_tuned = model_0.fit(trainData,\n",
        "                         epochs= 15,\n",
        "                         validation_data= testData,\n",
        "                         validation_steps= len(testData),\n",
        "                         steps_per_epoch= len(trainData),\n",
        "                         initial_epoch=history.epoch[-1])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoo6n+hRConETbCmNLByXE",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}